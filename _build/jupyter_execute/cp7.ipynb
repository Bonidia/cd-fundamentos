{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be810777",
   "metadata": {},
   "source": [
    "# Amostras de Dados para Experimentos\n",
    "\n",
    "```{admonition} Importante\n",
    ":class: tip\n",
    "Para execução dos códigos, é necessário instalar as seguintes bibliotecas: \n",
    "\n",
    " - *!pip install -U scikit-learn*\n",
    " - *!pip install -U imbalanced-learn*\n",
    "```\n",
    "\n",
    "## Procedimentos para Re-Amostragem de Dados - Hold-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d35b746e",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiabetes.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a70a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o método hold-out \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separando os dados em atributos preditivos (X) e atributo alvo (y)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Aplicando a técnica para hold-out \n",
    "training_set, test_set, train_labels, test_labels = train_test_split(X,  \n",
    "                                                                     y,  \n",
    "                                                                     test_size=0.3,\n",
    "                                                                     random_state=12,\n",
    "                                                                     stratify=y)\n",
    "\n",
    "# test_size -> Indica o tamanho do teste\n",
    "# random_state -> Fixa a geração de números aleatórios\n",
    "# stratify -> Mantém a proporção das classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe635d45",
   "metadata": {},
   "source": [
    "## Procedimentos para Re-Amostragem de Dados - Validação Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794f3fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o método StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Separando os dados em atributos preditivos (X) e atributo alvo (y)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Escolhendo o número de splits e semente do random_state\n",
    "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=20)\n",
    "\n",
    "# Utilizando um loop para selecionar os conjuntos de treino e teste\n",
    "for train_index, test_index in folds.split(X, y):\n",
    "    X_train, X_val = X[train_index], X[test_index]\n",
    "    y_train, y_val = y[train_index], y[test_index]\n",
    "    \n",
    "    # Observando o tamanho de cada conjunto amostrado\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_val.shape)\n",
    "    print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ed4d1c",
   "metadata": {},
   "source": [
    "## Procedimentos para Re-Amostragem de Dados - Deixe-Um-De-Fora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fb9c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o método deixe-um-de-fora\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "# Separando os dados em atributos preditivos (X) e atributo alvo (y)\n",
    "X = df.iloc[:, :-1].values # Atributos preditivos\n",
    "y = df.iloc[:, -1].values # Atributo alvo\n",
    "\n",
    "# Inicializando o método do deixe-um-de-fora\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Utilizando um loop para selecionar os conjuntos de treino e teste\n",
    "for train_index, test_index in loo.split(X, y):\n",
    "    X_train, X_val = X[train_index], X[test_index]\n",
    "    y_train, y_val = y[train_index], y[test_index]\n",
    "    \n",
    "    # Observando o tamanho de cada conjunto amostrado\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_val.shape)\n",
    "    print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30812ace",
   "metadata": {},
   "source": [
    "## Procedimentos para Re-Amostragem de Dados - Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6a9f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o método ShuffleSplit\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Separando os dados em atributos preditivos (X) e atributo alvo (y)\n",
    "X = df.iloc[:, :-1].values # Atributos preditivos\n",
    "y = df.iloc[:, -1].values # Atributo alvo\n",
    "\n",
    "# Inicializando o método para bootstrap com a definição da quantidade de vezes que a amostragem será feita, o tamanho do teste e a semente do random_state\n",
    "ss = ShuffleSplit(n_splits=1000, test_size=0.25, random_state=3)\n",
    "\n",
    "# Utilizando um loop para selecionar os conjuntos de treino e teste\n",
    "for train_index, test_index in ss.split(X, y):\n",
    "    X_train, X_val = X[train_index], X[test_index]\n",
    "    y_train, y_val = y[train_index], y[test_index]\n",
    "    \n",
    "    # Observando o tamanho de cada conjunto amostrado\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_val.shape)\n",
    "    print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e580e566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o método resample\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Separando os dados em atributos preditivos (X) e atributo alvo (y)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Aplicando o método de bootstrapping manualmente\n",
    "n_splits = 20\n",
    "for i in range(n_splits):\n",
    "    split = resample(X, n_samples=50, replace=True, stratify=y, random_state=0)\n",
    "    \n",
    "    # Observando o conjunto amostrado \n",
    "    print(split)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765943f7",
   "metadata": {},
   "source": [
    "## Dados Desbalanceados - Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6b0c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o método Counter para contagem dos exemplos das classes\n",
    "from collections import Counter\n",
    "\n",
    "# Separando os dados em atributos preditivos (X) e atributo alvo (y)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Verificando se o conjunto de dados é desbalanceado\n",
    "print('Dataset shape %s' % Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d92247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o método RUS\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Separando os dados em atributos preditivos (X) e atributo alvo (y)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Dividindo dados em treinamento e teste com hold-out\n",
    "train_set, test_set, train_labels, test_labels = train_test_split(X,  \n",
    "                                                                  y,  \n",
    "                                                                  test_size=0.3,\n",
    "                                                                  random_state=12,\n",
    "                                                                  stratify=y)\n",
    "\n",
    "# Aplicando RUS\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "train_res, train_labels_res = rus.fit_resample(train_set, train_labels)\n",
    "\n",
    "print('Dataset shape %s' % Counter(train_labels))\n",
    "print('Resampled dataset shape %s' % Counter(train_labels_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ee535d",
   "metadata": {},
   "source": [
    "## Dados Desbalanceados - Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb055513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o método ROS\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Separando os dados em atributos preditivos (X) e atributo alvo (y)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Dividindo dados em treinamento e teste com hold-out\n",
    "train_set, test_set, train_labels, test_labels = train_test_split(X,  \n",
    "                                                                  y,  \n",
    "                                                                  test_size=0.3,\n",
    "                                                                  random_state=12,\n",
    "                                                                  stratify=y)\n",
    "\n",
    "# Aplicando ROS\n",
    "rs = RandomOverSampler()\n",
    "train_res, train_labels_res = rs.fit_resample(train_set, train_labels)\n",
    "\n",
    "print('Dataset shape %s' % Counter(train_labels))\n",
    "print('Resampled dataset shape %s' % Counter(train_labels_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70dd3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o método SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Separando os dados em atributos preditivos (X) e atributo alvo (y)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Dividindo dados em treinamento e teste com hold-out\n",
    "train_set, test_set, train_labels, test_labels = train_test_split(X,  \n",
    "                                                                  y,  \n",
    "                                                                  test_size=0.3,\n",
    "                                                                  random_state=12,\n",
    "                                                                  stratify=y)\n",
    "\n",
    "# Aplicando Synthetic Minority Oversampling TEchnique (SMOTE)\n",
    "s = SMOTE()\n",
    "train_res, train_labels_res = s.fit_resample(train_set, train_labels)\n",
    "\n",
    "print('Dataset shape %s' % Counter(train_labels))\n",
    "print('Resampled dataset shape %s' % Counter(train_labels_res))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "source_map": [
   13,
   28,
   35,
   53,
   58,
   79,
   84,
   105,
   110,
   133,
   149,
   154,
   166,
   187,
   192,
   215
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}